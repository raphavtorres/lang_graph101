{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.tools.tavily_search.tool.TavilySearchResults'>\n",
      "tavily_search_results_json\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "print(type(tool))\n",
    "print(tool.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class Agent:\n",
    "  def __init__(self, model, tools, system=\"\"):\n",
    "    self.system = system  # saving system message as attribute\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"llm\", self.call_openai)\n",
    "    graph.add_node(\"action\", self.take_action)\n",
    "    graph.add_conditional_edges(\n",
    "      \"llm\",\n",
    "      self.exists_action,\n",
    "      {True: \"action\", False: END}  # depending on the function's return\n",
    "    )\n",
    "    graph.add_edge(\"action\", \"llm\")\n",
    "    graph.set_entry_point(\"llm\")\n",
    "    self.graph = graph.compile()\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "    self.model = model.bind_tools(tools)\n",
    "\n",
    "  def exists_action(self, state: AgentState):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0\n",
    "\n",
    "  def call_openai(self, state: AgentState):\n",
    "    messages = state['messages']\n",
    "    if self.system:\n",
    "      messages = [SystemMessage(content=self.system)] + messages\n",
    "    message = self.model.invoke(messages)\n",
    "    return {\"messages\": [message]}\n",
    "  \n",
    "  def take_action(self, state: AgentState):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    results = []\n",
    "    for t in tool_calls:\n",
    "      print(f\"Calling: {t}\")\n",
    "      if not t['name'] in self.tools:  # Check for bad tool name from LLM\n",
    "        print(\"\\n ....bad tool name....\")\n",
    "        result = \"bad tool name, retry\"  # Instruct LLM to retry if bad\n",
    "      else:\n",
    "        result = self.tools[t['name']].invoke(t['args'])\n",
    "      results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "      print(\"Back to the model!\")\n",
    "      return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(llm, [tool], system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pygraphviz\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "Image(agent.graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Campinas, SP'}, 'id': 'call_WuWm8GY2XddZQFEzDjSZvAPa', 'type': 'tool_call'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"What is the weather in Campinas, SP?\")]\n",
    "result = agent.graph.invoke({\"messages\": messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in Campinas, SP is as follows:\n",
      "\n",
      "- **Temperature**: 37.4°C (99.4°F)\n",
      "- **Condition**: Sunny\n",
      "- **Wind**: 4.9 mph (7.9 kph) from the East\n",
      "- **Humidity**: 19%\n",
      "- **Pressure**: 1011 mb\n",
      "- **Visibility**: 10 km\n",
      "- **UV Index**: 10.0 (high)\n",
      "\n",
      "For more detailed information, you can check [WeatherAPI](https://www.weatherapi.com/) or [Time and Date](https://www.timeanddate.com/weather/brazil/campinas/ext).\n"
     ]
    }
   ],
   "source": [
    "print(result['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
