{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import AnyMessage\n",
    "import operator\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "  messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Checkpointer for Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# if we refresh the code, the db will be lost, beacause is in memory\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage, SystemMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "class Agent:\n",
    "  def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "    self.system = system  # saving system message as attribute\n",
    "    graph = StateGraph(AgentState)\n",
    "    graph.add_node(\"llm\", self.call_openai)\n",
    "    graph.add_node(\"action\", self.take_action)\n",
    "    graph.add_conditional_edges(\n",
    "      \"llm\",\n",
    "      self.exists_action,\n",
    "      {True: \"action\", False: END}  # depending on the function's return\n",
    "    )\n",
    "    graph.add_edge(\"action\", \"llm\")\n",
    "    graph.set_entry_point(\"llm\")\n",
    "    self.graph = graph.compile(checkpointer=checkpointer)\n",
    "    self.tools = {t.name: t for t in tools}\n",
    "    self.model = model.bind_tools(tools)\n",
    "\n",
    "  def exists_action(self, state: AgentState):\n",
    "    result = state['messages'][-1]\n",
    "    return len(result.tool_calls) > 0\n",
    "\n",
    "  def call_openai(self, state: AgentState):\n",
    "    messages = state['messages']\n",
    "    if self.system:\n",
    "      messages = [SystemMessage(content=self.system)] + messages\n",
    "    message = self.model.invoke(messages)\n",
    "    return {\"messages\": [message]}\n",
    "  \n",
    "  def take_action(self, state: AgentState):\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    results = []\n",
    "    for t in tool_calls:\n",
    "      print(f\"Calling: {t}\")\n",
    "      if not t['name'] in self.tools:  # Check for bad tool name from LLM\n",
    "        print(\"\\n ....bad tool name....\")\n",
    "        result = \"bad tool name, retry\"  # Instruct LLM to retry if bad\n",
    "      else:\n",
    "        result = self.tools[t['name']].invoke(t['args'])\n",
    "      results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "      print(\"Back to the model!\")\n",
    "      return {'messages': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(llm, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messages = [HumanMessage(content=\"What is the weather in Campinas, SP?\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread Config\n",
    "\n",
    "Keep track of different threads inside the persistent checkpointer<br>\n",
    "Allows having multiple conversations at the same time<br>\n",
    "Important for production applications where you generally have many users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling agent with `.stream()` instead of `.involke()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_1OscbrpoFKaEzKzZN45flD8c', 'function': {'arguments': '{\"query\":\"current weather in Campinas, SP\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 153, 'total_tokens': 176}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_611b667b19', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b72d04ae-58b3-45f9-97d1-1a0732644ea8-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Campinas, SP'}, 'id': 'call_1OscbrpoFKaEzKzZN45flD8c', 'type': 'tool_call'}], usage_metadata={'input_tokens': 153, 'output_tokens': 23, 'total_tokens': 176})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Campinas, SP'}, 'id': 'call_1OscbrpoFKaEzKzZN45flD8c', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Campinas\\', \\'region\\': \\'Para\\', \\'country\\': \\'Brazil\\', \\'lat\\': -5.8, \\'lon\\': -48.33, \\'tz_id\\': \\'America/Araguaina\\', \\'localtime_epoch\\': 1722351151, \\'localtime\\': \\'2024-07-30 11:52\\'}, \\'current\\': {\\'last_updated_epoch\\': 1722350700, \\'last_updated\\': \\'2024-07-30 11:45\\', \\'temp_c\\': 37.4, \\'temp_f\\': 99.3, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Sunny\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 7.6, \\'wind_kph\\': 12.2, \\'wind_degree\\': 115, \\'wind_dir\\': \\'ESE\\', \\'pressure_mb\\': 1014.0, \\'pressure_in\\': 29.94, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 19, \\'cloud\\': 5, \\'feelslike_c\\': 36.2, \\'feelslike_f\\': 97.2, \\'windchill_c\\': 37.4, \\'windchill_f\\': 99.3, \\'heatindex_c\\': 36.2, \\'heatindex_f\\': 97.2, \\'dewpoint_c\\': 10.1, \\'dewpoint_f\\': 50.1, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 10.0, \\'gust_mph\\': 8.7, \\'gust_kph\\': 14.1}}\"}, {\\'url\\': \\'https://www.theweathernetwork.com/en/city/br/sao-paulo/campinas/7-days\\', \\'content\\': \\'See the Campinas, SP, BR extended weather forecast including feels like temperature, wind gust and chance of rain or snow from TheWeatherNetwork.com ... Tue Jul 30. Overnight. 15 Â° Feels 14\\'}]', name='tavily_search_results_json', tool_call_id='call_1OscbrpoFKaEzKzZN45flD8c')]\n",
      "[AIMessage(content='The current weather in Campinas, SP is as follows:\\n\\n- **Temperature**: 37.4Â°C (99.3Â°F)\\n- **Condition**: Sunny\\n- **Wind**: 12.2 kph (7.6 mph) from the ESE\\n- **Humidity**: 19%\\n- **Pressure**: 1014 mb\\n- **Visibility**: 10 km\\n- **UV Index**: 10.0 (very high)\\n\\nIt feels like 36.2Â°C (97.2Â°F). There is no precipitation expected.\\n\\nFor more details, you can check the full forecast on [WeatherAPI](https://www.weatherapi.com/) or [The Weather Network](https://www.theweathernetwork.com/en/city/br/sao-paulo/campinas/7-days).', response_metadata={'token_usage': {'completion_tokens': 169, 'prompt_tokens': 664, 'total_tokens': 833}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'stop', 'logprobs': None}, id='run-8c893db2-ce07-41b5-8ca7-616185b57a90-0', usage_metadata={'input_tokens': 664, 'output_tokens': 169, 'total_tokens': 833})]\n"
     ]
    }
   ],
   "source": [
    "for event in agent.graph.stream({\"messages\": messages}, thread_config):\n",
    "  for v in event.values():\n",
    "    print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_dPmG3wQzMvtouzvxPmOhj6Zl', 'function': {'arguments': '{\"query\":\"current weather in Valinhos, SP\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 845, 'total_tokens': 869}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0f03d4f0ee', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-dbda6c82-4837-49fe-bcfd-24fcfcf585bc-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Valinhos, SP'}, 'id': 'call_dPmG3wQzMvtouzvxPmOhj6Zl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 845, 'output_tokens': 24, 'total_tokens': 869})]}\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Valinhos, SP'}, 'id': 'call_dPmG3wQzMvtouzvxPmOhj6Zl', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "{'messages': [ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Valinhos\\', \\'region\\': \\'Parana\\', \\'country\\': \\'Brazil\\', \\'lat\\': -25.32, \\'lon\\': -50.36, \\'tz_id\\': \\'America/Sao_Paulo\\', \\'localtime_epoch\\': 1722351274, \\'localtime\\': \\'2024-07-30 11:54\\'}, \\'current\\': {\\'last_updated_epoch\\': 1722350700, \\'last_updated\\': \\'2024-07-30 11:45\\', \\'temp_c\\': 10.6, \\'temp_f\\': 51.2, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Mist\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/143.png\\', \\'code\\': 1030}, \\'wind_mph\\': 4.5, \\'wind_kph\\': 7.2, \\'wind_degree\\': 108, \\'wind_dir\\': \\'ESE\\', \\'pressure_mb\\': 1027.0, \\'pressure_in\\': 30.34, \\'precip_mm\\': 0.03, \\'precip_in\\': 0.0, \\'humidity\\': 95, \\'cloud\\': 100, \\'feelslike_c\\': 9.9, \\'feelslike_f\\': 49.9, \\'windchill_c\\': 9.9, \\'windchill_f\\': 49.9, \\'heatindex_c\\': 10.7, \\'heatindex_f\\': 51.2, \\'dewpoint_c\\': 9.9, \\'dewpoint_f\\': 49.9, \\'vis_km\\': 2.0, \\'vis_miles\\': 1.0, \\'uv\\': 4.0, \\'gust_mph\\': 6.4, \\'gust_kph\\': 10.3}}\"}, {\\'url\\': \\'https://world-weather.info/forecast/brazil/valinhos/july-2024/\\', \\'content\\': \\'Detailed âš¡ Valinhos Weather Forecast for July 2024 - day/night ðŸŒ¡ï¸ temperatures, precipitations - World-Weather.info. Add the current city. Search. Weather; Archive; Widgets Â°F. World; Brazil; Weather in Valinhos; Weather in Valinhos in July 2024. ... 30 +75Â° +59Â° 31 +77Â° +59Â° ...\\'}]', name='tavily_search_results_json', tool_call_id='call_dPmG3wQzMvtouzvxPmOhj6Zl')]}\n",
      "{'messages': [AIMessage(content='The current weather in Valinhos, SP is as follows:\\n\\n- **Temperature**: 10.6Â°C (51.2Â°F)\\n- **Condition**: Mist\\n- **Wind**: 7.2 kph (4.5 mph) from the ESE\\n- **Humidity**: 95%\\n- **Pressure**: 1027 mb\\n- **Visibility**: 2 km\\n- **UV Index**: 4.0 (moderate)\\n\\nIt feels like 9.9Â°C (49.9Â°F). There has been a slight amount of precipitation (0.03 mm).\\n\\nFor more details, you can check the full forecast on [WeatherAPI](https://www.weatherapi.com/) or [World Weather](https://world-weather.info/forecast/brazil/valinhos/july-2024/).', response_metadata={'token_usage': {'completion_tokens': 173, 'prompt_tokens': 1391, 'total_tokens': 1564}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_611b667b19', 'finish_reason': 'stop', 'logprobs': None}, id='run-f0e17c89-ba64-4503-a8ea-5f8cd09b13eb-0', usage_metadata={'input_tokens': 1391, 'output_tokens': 173, 'total_tokens': 1564})]}\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about Valinhos?\")]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in agent.graph.stream({\"messages\": messages}, thread):\n",
    "  for v in event.values():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting aiosqlite\n",
      "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\toa3ca\\desktop\\projects\\langgraph101\\.venv\\lib\\site-packages (from aiosqlite) (4.12.2)\n",
      "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: aiosqlite\n",
      "Successfully installed aiosqlite-0.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install aiosqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "agent = Agent(llm, [tool], system=prompt, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\toa3ca\\Desktop\\Projects\\langgraph101\\.venv\\Lib\\site-packages\\langchain_core\\_api\\beta_decorator.py:87: LangChainBetaWarning: This API is in beta and may change in the future.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'current weather in Campinas'}, 'id': 'call_hvJvwooA1JzJmbSdPU5U2Ahp', 'type': 'tool_call'}\n",
      "Back to the model!\n",
      "The| current| weather| in| Campinas|,| Brazil| is| as| follows|:\n",
      "\n",
      "|-| **|Temperature|**|:| |16|.|1|Â°C| (|60|.|9|Â°F|)\n",
      "|-| **|Condition|**|:| Part|ly| Cloud|y|\n",
      "|-| **|Wind|**|:| |13|.|0| mph| (|20|.|9| k|ph|)| from| the| southeast|\n",
      "|-| **|Humidity|**|:| |79|%\n",
      "|-| **|Pressure|**|:| |102|3| mb|\n",
      "|-| **|Visibility|**|:| |10| km|\n",
      "\n",
      "|For| more| detailed| information|,| you| can| check| [|Weather|API|](|https|://|www|.weather|api|.com|/)| or| [|Time| and| Date|](|https|://|www|.time|and|date|.com|/weather|/b|razil|/c|amp|inas|/ext|).|"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in Campinas?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "async for event in agent.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "  kind = event[\"event\"]\n",
    "  if kind == \"on_chat_model_stream\":\n",
    "    content = event[\"data\"][\"chunk\"].content\n",
    "    if content:\n",
    "      # Empty content in the context of OpenAI means\n",
    "      # that the model is asking for a tool to be invoked.\n",
    "      # So we only print non-empty content\n",
    "      print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
